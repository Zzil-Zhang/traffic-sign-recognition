"""
train_cnn.py - äº¤é€šæ ‡å¿—CNNæ¨¡å‹è®­ç»ƒè„šæœ¬
æˆå‘˜Bçš„ä¸»è¦ä»»åŠ¡ï¼šè®­ç»ƒæ·±åº¦CNNæ¨¡å‹
"""

import os
import numpy as np
import matplotlib.pyplot as plt
from datetime import datetime
import json

# Kerasç›¸å…³
from keras.utils import to_categorical
from keras.callbacks import ModelCheckpoint, EarlyStopping, ReduceLROnPlateau, TensorBoard
from keras.optimizers import Adam

# è‡ªå®šä¹‰æ¨¡å—
from data_preprocessing import GTSRBDataLoader
from cnn_model import create_traffic_cnn_model, create_simple_cnn_model, create_reference_model

class CNNTrainer:
    """CNNè®­ç»ƒå™¨ç±»ï¼Œå°è£…æ‰€æœ‰è®­ç»ƒé€»è¾‘"""
    
    def __init__(self, model_name='traffic_cnn', image_size=(64, 64)):
        """
        åˆå§‹åŒ–è®­ç»ƒå™¨
        model_name: æ¨¡å‹åç§°ï¼Œç”¨äºä¿å­˜æ–‡ä»¶
        image_size: å›¾åƒå°ºå¯¸
        """
        self.model_name = model_name
        self.image_size = image_size
        self.model = None
        self.history = None
        self.timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
        
        # åˆ›å»ºç›®å½•
        self.create_directories()
    
    def create_directories(self):
        """åˆ›å»ºå¿…è¦çš„ç›®å½•"""
        directories = [
            'trained_models',
            'training_logs',
            'training_results',
            'training_curves'
        ]
        for dir_name in directories:
            os.makedirs(dir_name, exist_ok=True)
    
    def load_data(self):
        """åŠ è½½æ•°æ® - ä½¿ç”¨æˆå‘˜Açš„æ•°æ®åŠ è½½å™¨"""
        print("=" * 60)
        print("æ­¥éª¤1: åŠ è½½æ•°æ®")
        print("=" * 60)
        
        try:
            # ä½¿ç”¨æˆå‘˜Açš„GTSRBDataLoader
            loader = GTSRBDataLoader(
                data_root='data',
                image_size=self.image_size,
                normalize='minmax'  # åƒç´ å€¼å½’ä¸€åŒ–åˆ°[0,1]
            )
            
            # åŠ è½½é¢„å¤„ç†æ•°æ®
            X_train, X_val, X_test, y_train, y_val, y_test = loader.load_processed_data('processed_data')
            
            print(f"âœ“ æ•°æ®åŠ è½½æˆåŠŸï¼")
            print(f"  è®­ç»ƒé›†: {X_train.shape} - {len(y_train)} å¼ å›¾ç‰‡")
            print(f"  éªŒè¯é›†: {X_val.shape} - {len(y_val)} å¼ å›¾ç‰‡")
            print(f"  æµ‹è¯•é›†: {X_test.shape} - {len(y_test)} å¼ å›¾ç‰‡")
            print(f"  åƒç´ å€¼èŒƒå›´: [{X_train.min():.3f}, {X_train.max():.3f}]")
            
            # è½¬æ¢ä¸ºone-hotç¼–ç ï¼ˆKeraséœ€è¦ï¼‰
            y_train_onehot = to_categorical(y_train, 43)
            y_val_onehot = to_categorical(y_val, 43)
            y_test_onehot = to_categorical(y_test, 43)
            
            return X_train, X_val, X_test, y_train_onehot, y_val_onehot, y_test_onehot
            
        except Exception as e:
            print(f"âœ— æ•°æ®åŠ è½½å¤±è´¥: {e}")
            print("è¯·ç¡®ä¿ï¼š")
            print("  1. å·²è¿è¡Œ data_preprocessing.py ç”Ÿæˆé¢„å¤„ç†æ•°æ®")
            print("  2. processed_data/ ç›®å½•åŒ…å«å¿…è¦çš„æ•°æ®æ–‡ä»¶")
            print("  3. data/ ç›®å½•åŒ…å«åŸå§‹æ•°æ®é›†")
            return None
    
    def create_model(self, model_type='standard'):
        """
        åˆ›å»ºCNNæ¨¡å‹
        model_type: 'standard', 'simple', æˆ– 'reference'
        """
        print("\n" + "=" * 60)
        print("æ­¥éª¤2: åˆ›å»ºCNNæ¨¡å‹")
        print("=" * 60)
        
        input_shape = (self.image_size[0], self.image_size[1], 3)
        
        if model_type == 'simple':
            self.model = create_simple_cnn_model(input_shape)
            print("ä½¿ç”¨: ç®€å•CNNæ¨¡å‹")
        elif model_type == 'reference':
            self.model = create_reference_model(input_shape)
            print("ä½¿ç”¨: å‚è€ƒé¡¹ç›®æ”¹è¿›æ¨¡å‹")
        else:
            self.model = create_traffic_cnn_model(input_shape)
            print("ä½¿ç”¨: æ ‡å‡†CNNæ¨¡å‹")
        
        # ç¼–è¯‘æ¨¡å‹
        optimizer = Adam(learning_rate=0.001)
        self.model.compile(
            optimizer=optimizer,
            loss='categorical_crossentropy',
            metrics=['accuracy']
        )
        
        print("æ¨¡å‹ç»“æ„:")
        self.model.summary()
        
        return self.model
    
    def train_model(self, X_train, y_train, X_val, y_val, epochs=30, batch_size=32):
        """
        è®­ç»ƒæ¨¡å‹
        """
        print("\n" + "=" * 60)
        print("æ­¥éª¤3: è®­ç»ƒæ¨¡å‹")
        print("=" * 60)
        
        # å›è°ƒå‡½æ•°
        callbacks = self.get_callbacks()
        
        print(f"è®­ç»ƒå‚æ•°:")
        print(f"  Epochs: {epochs}")
        print(f"  Batch Size: {batch_size}")
        print(f"  è®­ç»ƒæ ·æœ¬: {len(X_train)}")
        print(f"  éªŒè¯æ ·æœ¬: {len(X_val)}")
        
        # å¼€å§‹è®­ç»ƒ
        print("\nå¼€å§‹è®­ç»ƒ...")
        self.history = self.model.fit(
            X_train, y_train,
            batch_size=batch_size,
            epochs=epochs,
            validation_data=(X_val, y_val),
            callbacks=callbacks,
            verbose=1  # æ˜¾ç¤ºè¿›åº¦æ¡
        )
        
        print("âœ“ è®­ç»ƒå®Œæˆï¼")
        
        return self.history
    
    def get_callbacks(self):
        """è·å–è®­ç»ƒå›è°ƒå‡½æ•°"""
        # æ¨¡å‹ä¿å­˜è·¯å¾„
        model_path = f'trained_models/{self.model_name}_{self.timestamp}.keras'
        best_model_path = f'trained_models/{self.model_name}_best.keras'
        
        callbacks = [
            # ä¿å­˜æœ€ä½³æ¨¡å‹
            ModelCheckpoint(
                filepath=best_model_path,
                monitor='val_accuracy',
                save_best_only=True,
                mode='max',
                verbose=1,
                # save_format='keras'
            ),
            # æå‰åœæ­¢ï¼ˆé˜²æ­¢è¿‡æ‹Ÿåˆï¼‰
            EarlyStopping(
                monitor='val_accuracy',
                patience=10,  # 10ä¸ªepochæ²¡æœ‰æ”¹è¿›å°±åœæ­¢
                restore_best_weights=True,
                verbose=1
            ),
            # åŠ¨æ€è°ƒæ•´å­¦ä¹ ç‡
            ReduceLROnPlateau(
                monitor='val_loss',
                factor=0.5,    # å­¦ä¹ ç‡å‡åŠ
                patience=5,    # 5ä¸ªepochæ²¡æœ‰æ”¹è¿›å°±è°ƒæ•´
                min_lr=0.00001,
                verbose=1
            ),
            # TensorBoardæ—¥å¿—
            TensorBoard(
                log_dir=f'training_logs/{self.timestamp}',
                histogram_freq=1,
                write_graph=True,
                write_images=True,
                update_freq='epoch'
            )
        ]
        
        return callbacks
    
    def save_model(self):
        """ä¿å­˜æœ€ç»ˆæ¨¡å‹"""
        model_path = f'trained_models/{self.model_name}_final_{self.timestamp}.keras'
        self.model.save(model_path)
        print(f"âœ“ æœ€ç»ˆæ¨¡å‹å·²ä¿å­˜: {model_path}")
        
        # åŒæ—¶ä¿å­˜ä¸€ä¸ªç®€å•åç§°çš„å‰¯æœ¬
        simple_path = 'my_traffic_classifier.keras'
        self.model.save(simple_path)
        print(f"âœ“ æ¨¡å‹å·²ä¿å­˜ä¸º: {simple_path}")
        
        return model_path
    
    def plot_training_curves(self):
        """ç»˜åˆ¶è®­ç»ƒæ›²çº¿"""
        if self.history is None:
            print("æ²¡æœ‰è®­ç»ƒå†å²æ•°æ®")
            return
        
        history = self.history.history
        
        plt.figure(figsize=(14, 5))
        
        # 1. å‡†ç¡®ç‡æ›²çº¿
        plt.subplot(1, 2, 1)
        plt.plot(history['accuracy'], label='è®­ç»ƒå‡†ç¡®ç‡', linewidth=2)
        plt.plot(history['val_accuracy'], label='éªŒè¯å‡†ç¡®ç‡', linewidth=2)
        plt.title('æ¨¡å‹å‡†ç¡®ç‡', fontsize=14, fontweight='bold')
        plt.xlabel('Epoch', fontsize=12)
        plt.ylabel('Accuracy', fontsize=12)
        plt.legend(fontsize=11)
        plt.grid(True, alpha=0.3)
        
        # æ ‡è®°æœ€ä½³å‡†ç¡®ç‡
        best_val_acc = max(history['val_accuracy'])
        best_epoch = history['val_accuracy'].index(best_val_acc)
        plt.scatter(best_epoch, best_val_acc, color='red', s=100, zorder=5)
        plt.text(best_epoch, best_val_acc-0.05, f'{best_val_acc:.3f}', 
                fontsize=11, ha='center', color='red')
        
        # 2. æŸå¤±æ›²çº¿
        plt.subplot(1, 2, 2)
        plt.plot(history['loss'], label='è®­ç»ƒæŸå¤±', linewidth=2)
        plt.plot(history['val_loss'], label='éªŒè¯æŸå¤±', linewidth=2)
        plt.title('æ¨¡å‹æŸå¤±', fontsize=14, fontweight='bold')
        plt.xlabel('Epoch', fontsize=12)
        plt.ylabel('Loss', fontsize=12)
        plt.legend(fontsize=11)
        plt.grid(True, alpha=0.3)
        
        plt.tight_layout()
        
        # ä¿å­˜å›¾ç‰‡
        curve_path = f'training_curves/training_history_{self.timestamp}.png'
        plt.savefig(curve_path, dpi=150, bbox_inches='tight')
        plt.savefig('training_results.png', dpi=150, bbox_inches='tight')  # ç®€å•åç§°
        
        print(f"âœ“ è®­ç»ƒæ›²çº¿å·²ä¿å­˜: {curve_path}")
        plt.show()
    
    def save_training_report(self, X_test, y_test):
        """ä¿å­˜è®­ç»ƒæŠ¥å‘Š"""
        if self.model is None:
            print("æ²¡æœ‰æ¨¡å‹å¯ä»¥è¯„ä¼°")
            return
        
        # è¯„ä¼°æ¨¡å‹
        test_loss, test_accuracy = self.model.evaluate(X_test, y_test, verbose=0)
        train_accuracy = self.history.history['accuracy'][-1]
        val_accuracy = self.history.history['val_accuracy'][-1]
        best_val_accuracy = max(self.history.history['val_accuracy'])
        
        # åˆ›å»ºæŠ¥å‘Š
        report = {
            'model_name': self.model_name,
            'timestamp': self.timestamp,
            'image_size': self.image_size,
            'training_samples': len(self.history.history['accuracy']) * 32,  # ä¼°ç®—
            'final_train_accuracy': float(train_accuracy),
            'final_val_accuracy': float(val_accuracy),
            'best_val_accuracy': float(best_val_accuracy),
            'test_accuracy': float(test_accuracy),
            'test_loss': float(test_loss),
            'training_time_epochs': len(self.history.history['accuracy'])
        }
        
        # ä¿å­˜ä¸ºJSON
        report_path = f'training_results/training_report_{self.timestamp}.json'
        with open(report_path, 'w', encoding='utf-8') as f:
            json.dump(report, f, indent=4, ensure_ascii=False)
        
        # æ‰“å°æŠ¥å‘Š
        print("\n" + "=" * 60)
        print("è®­ç»ƒæŠ¥å‘Š")
        print("=" * 60)
        print(f"æ¨¡å‹åç§°: {report['model_name']}")
        print(f"è®­ç»ƒæ—¶é—´: {report['timestamp']}")
        print(f"å›¾åƒå°ºå¯¸: {report['image_size']}")
        print(f"è®­ç»ƒè½®æ•°: {report['training_time_epochs']}")
        print(f"æœ€ç»ˆè®­ç»ƒå‡†ç¡®ç‡: {report['final_train_accuracy']:.4f}")
        print(f"æœ€ç»ˆéªŒè¯å‡†ç¡®ç‡: {report['final_val_accuracy']:.4f}")
        print(f"æœ€ä½³éªŒè¯å‡†ç¡®ç‡: {report['best_val_accuracy']:.4f}")
        print(f"æµ‹è¯•é›†å‡†ç¡®ç‡: {report['test_accuracy']:.4f}")
        print(f"æµ‹è¯•é›†æŸå¤±: {report['test_loss']:.4f}")
        
        # åˆ¤æ–­æ˜¯å¦è¾¾åˆ°ç›®æ ‡
        target_accuracy = 0.85  # 85%çš„ç›®æ ‡
        if report['test_accuracy'] >= target_accuracy:
            print(f"ğŸ‰ æ­å–œï¼æµ‹è¯•å‡†ç¡®ç‡ ({report['test_accuracy']:.2%}) è¾¾åˆ°ç›®æ ‡ ({target_accuracy:.2%})")
        else:
            print(f"âš ï¸ æµ‹è¯•å‡†ç¡®ç‡ ({report['test_accuracy']:.2%}) æœªè¾¾åˆ°ç›®æ ‡ ({target_accuracy:.2%})")
        
        print(f"\nâœ“ è®­ç»ƒæŠ¥å‘Šå·²ä¿å­˜: {report_path}")
        
        return report

def main():
    """ä¸»å‡½æ•°"""
    print("\n" + "=" * 60)
    print("å¾·å›½äº¤é€šæ ‡å¿—è¯†åˆ« - CNNæ¨¡å‹è®­ç»ƒ")
    print("æˆå‘˜Bä»»åŠ¡ï¼šæ·±åº¦å­¦ä¹ æ¶æ„å¸ˆ & æ¨¡å‹è®­ç»ƒ")
    print("=" * 60)
    
    # 1. åˆ›å»ºè®­ç»ƒå™¨
    trainer = CNNTrainer(
        model_name='traffic_sign_cnn',
        image_size=(64, 64)  # ä¸æˆå‘˜Açš„é¢„å¤„ç†ä¿æŒä¸€è‡´
    )
    
    # 2. åŠ è½½æ•°æ®
    data = trainer.load_data()
    if data is None:
        print("æ•°æ®åŠ è½½å¤±è´¥ï¼Œè¯·æ£€æŸ¥æ•°æ®æ–‡ä»¶")
        return
    
    X_train, X_val, X_test, y_train, y_val, y_test = data
    
    # 3. åˆ›å»ºæ¨¡å‹ï¼ˆå¯ä»¥é€‰æ‹©ä¸åŒçš„æ¨¡å‹ç±»å‹ï¼‰
    # å¯é€‰: 'standard', 'simple', 'reference'
    trainer.create_model(model_type='standard')
    
    # 4. è®­ç»ƒæ¨¡å‹
    trainer.train_model(
        X_train, y_train,
        X_val, y_val,
        epochs=30,      # è®­ç»ƒè½®æ•°
        batch_size=32   # æ‰¹å¤§å°
    )
    
    # 5. ä¿å­˜æ¨¡å‹
    trainer.save_model()
    
    # 6. ç»˜åˆ¶è®­ç»ƒæ›²çº¿
    trainer.plot_training_curves()
    
    # 7. ä¿å­˜è®­ç»ƒæŠ¥å‘Š
    trainer.save_training_report(X_test, y_test)
    
    print("\n" + "=" * 60)
    print("è®­ç»ƒæµç¨‹å®Œæˆï¼")
    print("=" * 60)
    print("ä¸‹ä¸€æ­¥:")
    print("1. æŸ¥çœ‹è®­ç»ƒæ›²çº¿: training_results.png")
    print("2. æŸ¥çœ‹è®­ç»ƒæŠ¥å‘Š: training_results/ ç›®å½•")
    print("3. ä½¿ç”¨æ¨¡å‹: my_traffic_classifier.keras")
    print("4. å¯è§†åŒ–è®­ç»ƒè¿‡ç¨‹: tensorboard --logdir=training_logs")
    print("=" * 60)

if __name__ == "__main__":
    # æ£€æŸ¥ä¾èµ–
    try:
        import tensorflow as tf
        print(f"TensorFlowç‰ˆæœ¬: {tf.__version__}")
    except ImportError:
        print("é”™è¯¯: è¯·å…ˆå®‰è£…TensorFlow/Keras")
        print("è¿è¡Œ: pip install tensorflow")
        exit(1)
    
    # è¿è¡Œä¸»ç¨‹åº
    main()