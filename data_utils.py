# data_utils.py - å¢å¼ºç‰ˆæ•°æ®åŠ è½½å·¥å…·
import numpy as np
import os
import cv2
from paddle.io import Dataset, DataLoader
from paddle.vision.transforms import Compose, RandomHorizontalFlip, RandomRotation, ColorJitter, Normalize, Resize
import random
import paddle  # æ·»åŠ è¿™è¡Œï¼ï¼ï¼

def load_data_from_npy():
    """ä»npyæ–‡ä»¶åŠ è½½æ•°æ®"""
    print("ğŸ“‚ ä»processed_dataåŠ è½½é¢„å¤„ç†æ•°æ®...")
    
    try:
        X_train = np.load('processed_data/X_train.npy')
        X_val = np.load('processed_data/X_val.npy')
        X_test = np.load('processed_data/X_test.npy')
        y_train = np.load('processed_data/y_train.npy')
        y_val = np.load('processed_data/y_val.npy')
        y_test = np.load('processed_data/y_test.npy')
        
        # æ£€æŸ¥æ•°æ®å½¢çŠ¶
        print(f"âœ… æ•°æ®åŠ è½½æˆåŠŸï¼")
        print(f"  è®­ç»ƒé›†å½¢çŠ¶: {X_train.shape} - æ ‡ç­¾: {len(y_train)}")
        print(f"  éªŒè¯é›†å½¢çŠ¶: {X_val.shape} - æ ‡ç­¾: {len(y_val)}")
        print(f"  æµ‹è¯•é›†å½¢çŠ¶: {X_test.shape} - æ ‡ç­¾: {len(y_test)}")
        
        # æ£€æŸ¥æ•°æ®èŒƒå›´
        print(f"\nğŸ” æ•°æ®ç»Ÿè®¡:")
        print(f"  è®­ç»ƒé›†èŒƒå›´: [{X_train.min():.3f}, {X_train.max():.3f}]")
        print(f"  è®­ç»ƒé›†å‡å€¼: {X_train.mean():.3f}, æ ‡å‡†å·®: {X_train.std():.3f}")
        print(f"  æ ‡ç­¾å”¯ä¸€å€¼: {len(np.unique(y_train))}, èŒƒå›´: [{y_train.min()}, {y_train.max()}]")
        
        return (X_train, y_train), (X_val, y_val), (X_test, y_test)
    except Exception as e:
        print(f"âŒ æ•°æ®åŠ è½½å¤±è´¥: {e}")
        print("è¯·ç¡®ä¿å·²è¿è¡Œdata_preprocessing.pyé¢„å¤„ç†æ•°æ®")
        return None, None, None

class GTSRBDatasetPaddle(Dataset):
    """æ”¹è¿›çš„PaddlePaddleæ•°æ®é›†ç±»ï¼Œæ”¯æŒæ•°æ®å¢å¼º"""
    def __init__(self, images, labels, is_training=False, augment=False):
        """
        å‚æ•°:
            images: å›¾åƒæ•°æ®
            labels: æ ‡ç­¾æ•°æ®
            is_training: æ˜¯å¦ä¸ºè®­ç»ƒé›†
            augment: æ˜¯å¦è¿›è¡Œæ•°æ®å¢å¼º
        """
        # ç¡®ä¿å›¾åƒæ•°æ®æ˜¯float32
        self.images = images.astype('float32')
        self.labels = labels.astype('int64')
        self.is_training = is_training
        self.augment = augment
        
        # è·å–å›¾åƒå°ºå¯¸ä¿¡æ¯
        if len(self.images.shape) == 4:
            self.num_samples, self.height, self.width, self.channels = self.images.shape
        else:
            # å¦‚æœå·²ç»æ˜¯CHWæ ¼å¼
            self.num_samples, self.channels, self.height, self.width = self.images.shape
        
        # åˆ›å»ºæ•°æ®å¢å¼ºå˜æ¢ - é™ä½å¢å¼ºå¼ºåº¦ï¼Œé˜²æ­¢è¿‡æ‹Ÿåˆ
        if augment and is_training:
            self.transform = Compose([
                Resize((64, 64)),  # ç¡®ä¿å°ºå¯¸ä¸€è‡´
                RandomHorizontalFlip(prob=0.2),  # é™ä½ç¿»è½¬æ¦‚ç‡
                RandomRotation(degrees=5),  # é™ä½æ—‹è½¬è§’åº¦
                ColorJitter(brightness=0.1, contrast=0.1, saturation=0.1),  # é™ä½æ‰°åŠ¨å¼ºåº¦
                Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225], data_format='CHW')
            ])
        else:
            self.transform = Compose([
                Resize((64, 64)),  # ç¡®ä¿å°ºå¯¸ä¸€è‡´
                Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225], data_format='CHW')
            ])
    
    def __len__(self):
        return self.num_samples
    
    def __getitem__(self, idx):
        # è·å–å›¾åƒæ•°æ®
        img = self.images[idx]
        
        # å¦‚æœå›¾åƒåœ¨[0, 255]èŒƒå›´å†…ï¼Œå½’ä¸€åŒ–åˆ°[0, 1]
        if img.max() > 1.0:
            img = img / 255.0
        
        # ç¡®ä¿å›¾åƒæ˜¯CHWæ ¼å¼ (PaddlePaddleæœŸæœ›çš„æ ¼å¼)
        if len(img.shape) == 3 and img.shape[2] == 3:  # HWCæ ¼å¼
            img = img.transpose(2, 0, 1)  # è½¬æ¢ä¸ºCHW
        
        # è½¬æ¢ä¸ºpaddle tensor
        img = paddle.to_tensor(img)
        
        # åº”ç”¨å˜æ¢
        img = self.transform(img)
        
        # è·å–æ ‡ç­¾
        label = self.labels[idx]
        
        return img, label
    
    def visualize_sample(self, idx=0):
        """å¯è§†åŒ–æ ·æœ¬"""
        try:
            import matplotlib.pyplot as plt
            
            img, label = self.__getitem__(idx)
            
            # è½¬æ¢å›HWCæ ¼å¼æ˜¾ç¤º
            img_np = img.numpy()
            if len(img_np.shape) == 3 and img_np.shape[0] == 3:  # CHWæ ¼å¼
                img_np = img_np.transpose(1, 2, 0)  # è½¬æ¢ä¸ºHWC
            
            # åæ ‡å‡†åŒ–ç”¨äºæ˜¾ç¤º
            mean = np.array([0.485, 0.456, 0.406]).reshape(1, 1, 3)
            std = np.array([0.229, 0.224, 0.225]).reshape(1, 1, 3)
            img_display = (img_np * std) + mean
            img_display = np.clip(img_display, 0, 1)
            
            # è·å–åŸå§‹å›¾åƒï¼ˆæœªå¤„ç†ï¼‰
            raw_img = self.images[idx]
            if raw_img.max() > 1.0:
                raw_img_display = raw_img / 255.0
            else:
                raw_img_display = raw_img
            
            # å¦‚æœåŸå§‹å›¾åƒæ˜¯CHWæ ¼å¼ï¼Œè½¬æ¢ä¸ºHWC
            if len(raw_img_display.shape) == 3 and raw_img_display.shape[0] == 3:
                raw_img_display = raw_img_display.transpose(1, 2, 0)
            
            plt.figure(figsize=(8, 4))
            plt.subplot(1, 2, 1)
            plt.imshow(raw_img_display)
            plt.title(f"åŸå§‹æ ·æœ¬ {idx} - æ ‡ç­¾: {self.labels[idx]}")
            plt.axis('off')
            
            plt.subplot(1, 2, 2)
            plt.imshow(img_display)
            plt.title(f"å¤„ç†åæ ·æœ¬ {idx} - æ ‡ç­¾: {label}")
            plt.axis('off')
            
            plt.tight_layout()
            plt.show()
            
        except ImportError:
            print("matplotlibæœªå®‰è£…ï¼Œæ— æ³•æ˜¾ç¤ºå›¾åƒ")
        except Exception as e:
            print(f"å¯è§†åŒ–å¤±è´¥: {e}")

def create_data_loaders(batch_size=32, augment_train=True):
    """åˆ›å»ºæ•°æ®åŠ è½½å™¨"""
    print("ğŸ”„ æ­£åœ¨åŠ è½½æ•°æ®...")
    
    # å°è¯•ä»npyæ–‡ä»¶åŠ è½½æ•°æ®
    train_data, val_data, test_data = load_data_from_npy()
    
    # å¦‚æœåŠ è½½å¤±è´¥ï¼Œåˆ›å»ºç¤ºä¾‹æ•°æ®ç”¨äºæµ‹è¯•
    if train_data is None:
        print("âš ï¸  æ— æ³•ä»æ–‡ä»¶åŠ è½½æ•°æ®ï¼Œåˆ›å»ºç¤ºä¾‹æ•°æ®ç”¨äºæµ‹è¯•...")
        
        # åˆ›å»ºç¤ºä¾‹æ•°æ®
        num_train = 500
        num_val = 100
        num_test = 100
        
        # éšæœºç”Ÿæˆå›¾åƒæ•°æ®
        X_train = np.random.randn(num_train, 64, 64, 3).astype('float32') * 0.1 + 0.5
        X_train = np.clip(X_train, 0, 1) * 255  # æ¨¡æ‹Ÿ[0,255]èŒƒå›´
        y_train = np.random.randint(0, 43, num_train).astype('int64')
        
        X_val = np.random.randn(num_val, 64, 64, 3).astype('float32') * 0.1 + 0.5
        X_val = np.clip(X_val, 0, 1) * 255
        y_val = np.random.randint(0, 43, num_val).astype('int64')
        
        X_test = np.random.randn(num_test, 64, 64, 3).astype('float32') * 0.1 + 0.5
        X_test = np.clip(X_test, 0, 1) * 255
        y_test = np.random.randint(0, 43, num_test).astype('int64')
        
        train_data = (X_train, y_train)
        val_data = (X_val, y_val)
        test_data = (X_test, y_test)
    
    # è§£åŒ…æ•°æ®
    X_train, y_train = train_data
    X_val, y_val = val_data
    X_test, y_test = test_data
    
    # æ£€æŸ¥æ•°æ®åˆ†å¸ƒ
    print(f"\nğŸ“Š æ•°æ®åˆ†å¸ƒç»Ÿè®¡:")
    for name, X, y in [("è®­ç»ƒé›†", X_train, y_train), 
                       ("éªŒè¯é›†", X_val, y_val), 
                       ("æµ‹è¯•é›†", X_test, y_test)]:
        unique, counts = np.unique(y, return_counts=True)
        print(f"  {name}: {len(y)} æ ·æœ¬, {len(unique)} ä¸ªç±»åˆ«")
    
    # åˆ›å»ºæ•°æ®é›†
    print("\nğŸ› ï¸  åˆ›å»ºæ•°æ®é›†...")
    train_dataset = GTSRBDatasetPaddle(X_train, y_train, is_training=True, augment=augment_train)
    val_dataset = GTSRBDatasetPaddle(X_val, y_val, is_training=False)
    test_dataset = GTSRBDatasetPaddle(X_test, y_test, is_training=False)
    
    # åˆ›å»ºæ•°æ®åŠ è½½å™¨
    print("ğŸ”„ åˆ›å»ºæ•°æ®åŠ è½½å™¨...")
    
    # è®­ç»ƒé›†ä½¿ç”¨æ›´éšæœºçš„shuffle
    train_loader = DataLoader(
        train_dataset, 
        batch_size=batch_size, 
        shuffle=True,
        drop_last=True,  # ä¸¢å¼ƒæœ€åä¸å®Œæ•´çš„æ‰¹æ¬¡ï¼Œç¨³å®šè®­ç»ƒ
        num_workers=0
    )
    
    val_loader = DataLoader(
        val_dataset, 
        batch_size=batch_size,
        shuffle=False,
        num_workers=0
    )
    
    test_loader = DataLoader(
        test_dataset, 
        batch_size=batch_size,
        shuffle=False,
        num_workers=0
    )
    
    # æ˜¾ç¤ºä¸€ä¸ªæ ·æœ¬ç”¨äºéªŒè¯
    if len(train_dataset) > 0:
        print("\nğŸ‘ï¸  æ˜¾ç¤ºä¸€ä¸ªè®­ç»ƒæ ·æœ¬ç”¨äºéªŒè¯:")
        train_dataset.visualize_sample(0)
    
    return train_loader, val_loader, test_loader, (X_train, y_train, X_val, y_val, X_test, y_test)

def verify_data_consistency():
    """éªŒè¯æ•°æ®ä¸€è‡´æ€§"""
    print("\nğŸ” æ•°æ®ä¸€è‡´æ€§æ£€æŸ¥...")
    
    try:
        # æ£€æŸ¥æ˜¯å¦æœ‰é‡å¤æ•°æ®
        from sklearn.metrics.pairwise import cosine_similarity
        
        X_train = np.load('processed_data/X_train.npy')
        X_val = np.load('processed_data/X_val.npy')
        
        # éšæœºæ£€æŸ¥å‡ ä¸ªæ ·æœ¬
        n_check = min(10, len(X_train), len(X_val))
        
        for i in range(n_check):
            train_img = X_train[i].flatten()
            val_img = X_val[i].flatten()
            
            if np.array_equal(train_img, val_img):
                print(f"âš ï¸  å‘ç°é‡å¤æ•°æ®: è®­ç»ƒé›†æ ·æœ¬{i}å’ŒéªŒè¯é›†æ ·æœ¬{i}ç›¸åŒï¼")
        
        print("âœ… æ•°æ®ä¸€è‡´æ€§æ£€æŸ¥å®Œæˆ")
        
    except Exception as e:
        print(f"âŒ æ•°æ®ä¸€è‡´æ€§æ£€æŸ¥å¤±è´¥: {e}")

# åœ¨æ–‡ä»¶æœ«å°¾æ·»åŠ æµ‹è¯•ä»£ç 
if __name__ == "__main__":
    print("æµ‹è¯•æ•°æ®åŠ è½½å™¨...")
    
    # æµ‹è¯•æ•°æ®åŠ è½½
    train_loader, val_loader, test_loader, data_info = create_data_loaders(batch_size=16)
    
    if train_loader is not None:
        X_train, y_train, X_val, y_val, X_test, y_test = data_info
        
        print(f"\nâœ… æ•°æ®åŠ è½½æˆåŠŸ:")
        print(f"  è®­ç»ƒæ‰¹æ¬¡æ•°é‡: {len(train_loader)}")
        print(f"  éªŒè¯æ‰¹æ¬¡æ•°é‡: {len(val_loader)}")
        print(f"  æµ‹è¯•æ‰¹æ¬¡æ•°é‡: {len(test_loader)}")
        
        # éªŒè¯ä¸€ä¸ªæ‰¹æ¬¡
        for images, labels in train_loader:
            print(f"\nä¸€ä¸ªæ‰¹æ¬¡çš„å½¢çŠ¶:")
            print(f"  å›¾åƒ: {images.shape}, èŒƒå›´: [{images.min().item():.3f}, {images.max().item():.3f}]")
            print(f"  æ ‡ç­¾: {labels.shape}, èŒƒå›´: {labels.min().item()}åˆ°{labels.max().item()}")
            break