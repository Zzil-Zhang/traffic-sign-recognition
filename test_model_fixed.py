# test_model_fixed.py - å®Œæ•´ä¿®å¤ç‰ˆ
import numpy as np
import tensorflow as tf
import matplotlib.pyplot as plt
import cv2
import os

print("=" * 60)
print("ğŸš¦ å¾·å›½äº¤é€šæ ‡å¿—è¯†åˆ«ç³»ç»Ÿ - ä¿®å¤ç‰ˆ")
print("=" * 60)

# è®¾ç½®ä¸­æ–‡å­—ä½“ï¼ˆé¿å…æ–¹æ¡†ï¼‰
plt.rcParams['font.sans-serif'] = ['SimHei', 'Microsoft YaHei', 'DejaVu Sans']
plt.rcParams['axes.unicode_minus'] = False

# åŠ è½½æ¨¡å‹
model = tf.keras.models.load_model('my_traffic_classifier.keras')
print("âœ… æ¨¡å‹åŠ è½½æˆåŠŸ")

# ç±»åˆ«åç§°ï¼ˆä¸­æ–‡ï¼‰
class_names_cn = [
    'é™é€Ÿ20', 'é™é€Ÿ30', 'é™é€Ÿ50', 'é™é€Ÿ60', 'é™é€Ÿ70', 'é™é€Ÿ80',
    'é™é€Ÿè§£é™¤', 'é™é€Ÿ100', 'é™é€Ÿ120', 'è¶…è½¦ç¦æ­¢', 'å¡è½¦é™é€Ÿ',
    'ä¼˜å…ˆé“è·¯', 'è®©è¡Œ', 'åœæ­¢', 'ç¦æ­¢é€šè¡Œ', 'å¡è½¦ç¦æ­¢',
    'ç¦æ­¢é©¶å…¥', 'æ³¨æ„å±é™©', 'å·¦æ€¥å¼¯', 'å³æ€¥å¼¯', 'è¿ç»­å¼¯è·¯',
    'ä¸å¹³è·¯é¢', 'æ‰“æ»‘', 'å˜çª„', 'æ–½å·¥', 'ä¿¡å·ç¯', 'æ³¨æ„è¡Œäºº',
    'æ³¨æ„å„¿ç«¥', 'æ³¨æ„è‡ªè¡Œè½¦', 'æ³¨æ„é›ª/å†°', 'æ³¨æ„åŠ¨ç‰©',
    'è§£é™¤é™é€Ÿ', 'å³è½¬', 'å·¦è½¬', 'ç›´è¡Œ', 'ç›´è¡Œæˆ–å³è½¬',
    'ç›´è¡Œæˆ–å·¦è½¬', 'é å³è¡Œé©¶', 'é å·¦è¡Œé©¶', 'ç¯å²›',
    'è¶…è½¦è§£é™¤', 'å¡è½¦è¶…è½¦è§£é™¤'
]


def preprocess_image(image_path, target_size=(64, 64)):
    """æ­£ç¡®çš„å›¾åƒé¢„å¤„ç†"""
    # è¯»å–å›¾åƒ
    img = cv2.imread(image_path)
    if img is None:
        raise ValueError(f"æ— æ³•è¯»å–å›¾åƒ: {image_path}")

    # è½¬æ¢ä¸ºRGB
    img_rgb = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)

    # ä¿å­˜åŸå§‹å›¾åƒç”¨äºæ˜¾ç¤º
    original_img = img_rgb.copy()

    # é¢„å¤„ç†ï¼ˆä¸è®­ç»ƒæ—¶ä¸€è‡´ï¼‰
    # 1. è°ƒæ•´å¤§å°
    img_resized = cv2.resize(img_rgb, target_size)

    # 2. å½’ä¸€åŒ–åˆ°[0,1]
    img_normalized = img_resized.astype(np.float32) / 255.0

    # 3. ç¡®ä¿å½¢çŠ¶æ­£ç¡®
    if len(img_normalized.shape) == 3:
        img_normalized = np.expand_dims(img_normalized, axis=0)

    return original_img, img_resized, img_normalized


def predict_with_explanation(image_path):
    """å¸¦è¯¦ç»†è§£é‡Šçš„é¢„æµ‹"""
    print(f"\nğŸ“¸ æ­£åœ¨è¯†åˆ«: {os.path.basename(image_path)}")

    try:
        # é¢„å¤„ç†
        original_img, resized_img, input_img = preprocess_image(image_path)

        # é¢„æµ‹
        predictions = model.predict(input_img, verbose=0)
        predicted_class = np.argmax(predictions[0])
        confidence = predictions[0][predicted_class]

        # è·å–top3é¢„æµ‹
        top3_indices = np.argsort(predictions[0])[-3:][::-1]
        top3_confidences = predictions[0][top3_indices]

        print(f"âœ… é¢„æµ‹ç»“æœ: ç±»åˆ«{predicted_class} - {class_names_cn[predicted_class]}")
        print(f"ğŸ“Š ç½®ä¿¡åº¦: {confidence:.2%}")

        if confidence < 0.5:
            print("âš ï¸ ç½®ä¿¡åº¦è¾ƒä½ï¼å¯èƒ½åŸå› :")
            print("  1. å›¾åƒä¸æ˜¯å¾·å›½äº¤é€šæ ‡å¿—")
            print("  2. å›¾åƒè´¨é‡å·®æˆ–å°ºå¯¸ä¸å¯¹")
            print("  3. æ ‡å¿—ä¸åœ¨43ä¸ªè®­ç»ƒç±»åˆ«ä¸­")
            print("  4. å›¾åƒéœ€è¦é¢„å¤„ç†ï¼ˆè£å‰ªã€è°ƒæ•´å¤§å°ï¼‰")

        print(f"\nğŸ† å‰ä¸‰åé¢„æµ‹:")
        for i, (idx, conf) in enumerate(zip(top3_indices, top3_confidences)):
            print(f"  {i + 1}. ç±»åˆ«{idx}: {class_names_cn[idx]} ({conf:.2%})")

        # === æ˜¾ç¤ºå›¾åƒ ===
        fig, axes = plt.subplots(1, 3, figsize=(15, 5))

        # åŸå§‹å›¾åƒ
        axes[0].imshow(original_img)
        axes[0].set_title('åŸå§‹å›¾åƒ', fontsize=12)
        axes[0].axis('off')

        # é¢„å¤„ç†åçš„å›¾åƒï¼ˆæ¨¡å‹çœ‹åˆ°çš„ï¼‰
        axes[1].imshow(resized_img)
        axes[1].set_title('æ¨¡å‹è¾“å…¥ (64x64)', fontsize=12)
        axes[1].axis('off')

        # æ·»åŠ è§£é‡Š
        if original_img.shape[0] > 100 or original_img.shape[1] > 100:
            axes[1].text(32, 70, 'è®­ç»ƒå›¾åƒå°±æ˜¯64x64\nå¤§å›¾ç¼©å°åæ¨¡ç³Šæ˜¯æ­£å¸¸çš„',
                         ha='center', va='center', fontsize=10,
                         bbox=dict(boxstyle="round,pad=0.3", facecolor="yellow", alpha=0.5))

        # é¢„æµ‹ç»“æœæ¡å½¢å›¾
        colors = ['#2ecc71', '#f39c12', '#e74c3c']  # ç»¿ã€æ©™ã€çº¢
        bars = axes[2].barh(range(3), top3_confidences * 100, color=colors)
        axes[2].set_xlabel('ç½®ä¿¡åº¦ (%)', fontsize=11)
        axes[2].set_yticks(range(3))
        axes[2].set_yticklabels([f'{class_names_cn[idx]}'
                                 for idx in top3_indices], fontsize=10)

        if confidence > 0.8:
            title_color = 'green'
        elif confidence > 0.5:
            title_color = 'orange'
        else:
            title_color = 'red'

        axes[2].set_title(f'é¢„æµ‹ç»“æœ\næœ€ä½³: {class_names_cn[predicted_class]}',
                          fontsize=12, color=title_color, fontweight='bold')
        axes[2].set_xlim([0, 100])

        # åœ¨æ¡å½¢ä¸Šæ˜¾ç¤ºæ•°å€¼
        for bar, conf in zip(bars, top3_confidences):
            width = bar.get_width()
            axes[2].text(width + 1, bar.get_y() + bar.get_height() / 2,
                         f'{conf:.1%}', ha='left', va='center', fontsize=9)

        plt.suptitle(f'äº¤é€šæ ‡å¿—è¯†åˆ«ç»“æœ', fontsize=14, fontweight='bold')
        plt.tight_layout()
        plt.savefig('è¯†åˆ«ç»“æœ.png', dpi=150, bbox_inches='tight')
        plt.show()

        return predicted_class, confidence

    except Exception as e:
        print(f"âŒ é”™è¯¯: {e}")
        return None, 0


def test_with_sample_images():
    """ä½¿ç”¨æµ‹è¯•é›†ä¸­çš„å›¾åƒæµ‹è¯•ï¼ˆçœŸæ­£çš„äº¤é€šæ ‡å¿—ï¼‰"""
    print("\nğŸ¯ ä»æµ‹è¯•é›†éšæœºé€‰æ‹©å›¾åƒæµ‹è¯•...")

    try:
        # åŠ è½½æµ‹è¯•æ•°æ®
        X_test = np.load('processed_data/X_test.npy')
        y_test = np.load('processed_data/y_test.npy')

        # éšæœºé€‰æ‹©5å¼ 
        indices = np.random.choice(len(X_test), 5, replace=False)

        fig, axes = plt.subplots(2, 3, figsize=(15, 8))
        axes = axes.flatten()

        correct_count = 0

        for i, idx in enumerate(indices):
            img = X_test[idx]
            true_label = y_test[idx]

            # é¢„æµ‹
            predictions = model.predict(img[np.newaxis, ...], verbose=0)
            pred_label = np.argmax(predictions[0])
            confidence = predictions[0][pred_label]

            # æ˜¾ç¤ºå›¾åƒ
            axes[i].imshow(img)

            # åˆ¤æ–­æ˜¯å¦æ­£ç¡®
            correct = pred_label == true_label
            color = 'green' if correct else 'red'

            if correct:
                correct_count += 1

            title = f'çœŸ: {class_names_cn[true_label]}\n'
            title += f'é¢„æµ‹: {class_names_cn[pred_label]}\n'
            title += f'ç½®ä¿¡åº¦: {confidence:.1%}'

            axes[i].set_title(title, color=color, fontsize=9)
            axes[i].axis('off')

            # åœ¨å›¾åƒä¸Šæ˜¾ç¤ºå¯¹é”™ç¬¦å·
            symbol = 'âœ…' if correct else 'âŒ'
            axes[i].text(5, 15, symbol, fontsize=12, color=color,
                         bbox=dict(boxstyle="circle,pad=0.3", facecolor="white", alpha=0.8))

        # éšè—å¤šä½™çš„å­å›¾
        for i in range(len(indices), len(axes)):
            axes[i].axis('off')

        accuracy = correct_count / len(indices)
        plt.suptitle(f'æµ‹è¯•é›†éšæœºæ ·æœ¬ ({correct_count}/{len(indices)} æ­£ç¡®, å‡†ç¡®ç‡: {accuracy:.1%})',
                     fontsize=14, fontweight='bold')
        plt.tight_layout()
        plt.savefig('æµ‹è¯•é›†è¯†åˆ«.png', dpi=150, bbox_inches='tight')
        plt.show()

        print(f"\nğŸ“Š éšæœºæµ‹è¯•ç»“æœ: {correct_count}/{len(indices)} æ­£ç¡® ({accuracy:.1%})")

    except Exception as e:
        print(f"âŒ æµ‹è¯•é”™è¯¯: {e}")


def batch_test():
    """æ‰¹é‡æµ‹è¯•æ•´ä¸ªæµ‹è¯•é›†"""
    print("\nğŸ“Š æ‰¹é‡æµ‹è¯•æ•´ä¸ªæµ‹è¯•é›†...")

    try:
        X_test = np.load('processed_data/X_test.npy')
        y_test = np.load('processed_data/y_test.npy')
        y_test_onehot = tf.keras.utils.to_categorical(y_test, 43)

        # è¯„ä¼°
        loss, accuracy = model.evaluate(X_test, y_test_onehot, verbose=0)
        print(f"âœ… æµ‹è¯•é›†å‡†ç¡®ç‡: {accuracy:.4f} ({accuracy:.2%})")
        print(f"ğŸ“‰ æµ‹è¯•é›†æŸå¤±: {loss:.4f}")

        # é¢„æµ‹æ‰€æœ‰æ ·æœ¬
        predictions = model.predict(X_test, verbose=0)
        pred_labels = np.argmax(predictions, axis=1)

        # è®¡ç®—æ¯ä¸ªç±»åˆ«çš„å‡†ç¡®ç‡
        class_correct = np.zeros(43)
        class_total = np.zeros(43)

        for i in range(len(y_test)):
            class_total[y_test[i]] += 1
            if pred_labels[i] == y_test[i]:
                class_correct[y_test[i]] += 1

        print("\nğŸ“ˆ å„ç±»åˆ«å‡†ç¡®ç‡ (å‰10ä¸ª):")
        for i in range(min(10, 43)):
            if class_total[i] > 0:
                acc = class_correct[i] / class_total[i]
                stars = 'â˜…' * int(acc * 5) + 'â˜†' * (5 - int(acc * 5))
                print(f"  ç±»åˆ«{i:2d} {class_names_cn[i]:8s}: {stars} {acc:.1%}")

        # æ˜¾ç¤ºæ··æ·†çŸ©é˜µï¼ˆç®€ç‰ˆï¼‰
        print("\nğŸ” å¸¸è§æ··æ·†æƒ…å†µ:")
        confusion_pairs = []
        for i in range(len(y_test)):
            if pred_labels[i] != y_test[i]:
                confusion_pairs.append((y_test[i], pred_labels[i]))

        if confusion_pairs:
            from collections import Counter
            top_confusions = Counter(confusion_pairs).most_common(3)
            for (true, pred), count in top_confusions:
                print(f"  {class_names_cn[true]} â†’ {class_names_cn[pred]}: {count}æ¬¡")

        return accuracy

    except Exception as e:
        print(f"âŒ æ‰¹é‡æµ‹è¯•é”™è¯¯: {e}")
        return 0


def test_valid_image_folder():
    """æµ‹è¯•valid_imageæ–‡ä»¶å¤¹"""
    valid_dir = 'valid_image'

    if not os.path.exists(valid_dir):
        print(f"ğŸ“‚ æ–‡ä»¶å¤¹ä¸å­˜åœ¨: {valid_dir}/")
        print("ğŸ’¡ æç¤º: åˆ›å»º valid_image/ æ–‡ä»¶å¤¹ï¼Œæ”¾å…¥è¦æµ‹è¯•çš„å›¾åƒ")
        os.makedirs(valid_dir, exist_ok=True)
        print(f"âœ… å·²åˆ›å»º {valid_dir}/ æ–‡ä»¶å¤¹")
        return

    images = [f for f in os.listdir(valid_dir)
              if f.endswith(('.png', '.jpg', '.jpeg', '.ppm', '.bmp'))]

    if not images:
        print(f"ğŸ“­ {valid_dir}/ æ–‡ä»¶å¤¹æ˜¯ç©ºçš„")
        print("ğŸ’¡ è¯·æ”¾å…¥è¦æµ‹è¯•çš„äº¤é€šæ ‡å¿—å›¾åƒ")
        return

    print(f"\nğŸ“ åœ¨ {valid_dir}/ æ‰¾åˆ° {len(images)} å¼ å›¾åƒ:")

    results = []
    for img_file in images[:5]:  # åªæµ‹è¯•å‰5å¼ 
        img_path = os.path.join(valid_dir, img_file)
        print(f"\n{'=' * 40}")
        print(f"æµ‹è¯•: {img_file}")

        try:
            pred_class, confidence = predict_with_explanation(img_path)
            if pred_class is not None:
                results.append((img_file, pred_class, confidence, confidence > 0.5))
        except Exception as e:
            print(f"âŒ æµ‹è¯•å¤±è´¥: {e}")

    if results:
        print(f"\n{'=' * 40}")
        print("ğŸ“‹ æµ‹è¯•æ€»ç»“:")
        correct = sum(1 for _, _, conf, correct in results if correct)
        total = len(results)
        print(f"âœ… é«˜ç½®ä¿¡åº¦è¯†åˆ«: {correct}/{total}")

        for img_file, pred_class, confidence, is_correct in results:
            status = "âœ…" if is_correct else "âš ï¸"
            print(f"  {status} {img_file}: {class_names_cn[pred_class]} ({confidence:.1%})")


def main():
    """ä¸»å‡½æ•° - ä¸­æ–‡ç‰ˆ"""
    print("ğŸ¯ æ¨¡å‹ä¿¡æ¯:")
    print(f"  æµ‹è¯•å‡†ç¡®ç‡: 99.74%")
    print(f"  å¯è¯†åˆ«: 43ç§å¾·å›½äº¤é€šæ ‡å¿—")
    print(f"  è®­ç»ƒæ ·æœ¬: 39209å¼ å›¾åƒ")

    while True:
        print("\n" + "=" * 60)
        print("ğŸš¦ å¾·å›½äº¤é€šæ ‡å¿—è¯†åˆ«ç³»ç»Ÿ")
        print("=" * 60)
        print("è¯·é€‰æ‹©æ“ä½œ:")
        print("1. ğŸ–¼ï¸  è¯†åˆ«å•å¼ å›¾åƒ")
        print("2. ğŸ¯  æµ‹è¯•çœŸæ­£çš„äº¤é€šæ ‡å¿—ï¼ˆä»æµ‹è¯•é›†ï¼‰")
        print("3. ğŸ“  æµ‹è¯•valid_imageæ–‡ä»¶å¤¹")
        print("4. ğŸ“Š  æ‰¹é‡æµ‹è¯•æ•´ä¸ªæµ‹è¯•é›†")
        print("5. â„¹ï¸  æŸ¥çœ‹æ¨¡å‹ä¿¡æ¯")
        print("6. ğŸšª  é€€å‡º")
        print("=" * 60)

        choice = input("è¯·è¾“å…¥é€‰é¡¹ (1-6): ").strip()

        if choice == '1':
            img_path = input("è¯·è¾“å…¥å›¾åƒè·¯å¾„ (ç›´æ¥å›è½¦æµ‹è¯•00065.png): ").strip()
            if not img_path:
                if os.path.exists('00065.png'):
                    img_path = '00065.png'
                    print(f"ä½¿ç”¨é»˜è®¤å›¾åƒ: {img_path}")
                else:
                    print("âŒ 00065.pngä¸å­˜åœ¨ï¼Œè¯·æ‰‹åŠ¨è¾“å…¥è·¯å¾„")
                    continue

            if os.path.exists(img_path):
                predict_with_explanation(img_path)
            else:
                print(f"âŒ æ–‡ä»¶ä¸å­˜åœ¨: {img_path}")

        elif choice == '2':
            test_with_sample_images()

        elif choice == '3':
            test_valid_image_folder()

        elif choice == '4':
            batch_test()

        elif choice == '5':
            print("\nâ„¹ï¸ æ¨¡å‹è¯¦ç»†ä¿¡æ¯:")
            print(f"  è¾“å…¥å½¢çŠ¶: {model.input_shape}")
            print(f"  è¾“å‡ºå½¢çŠ¶: {model.output_shape}")
            print(f"  æ€»å‚æ•°: {model.count_params():,}")
            print(f"  å±‚æ•°: {len(model.layers)}")
            print(f"  è®­ç»ƒå‡†ç¡®ç‡: 99.79%")
            print(f"  éªŒè¯å‡†ç¡®ç‡: 99.73%")
            print(f"  æµ‹è¯•å‡†ç¡®ç‡: 99.74%")
            print(f"  è®­ç»ƒæ ·æœ¬: 27446å¼ ")
            print(f"  éªŒè¯æ ·æœ¬: 5881å¼ ")
            print(f"  æµ‹è¯•æ ·æœ¬: 5882å¼ ")

        elif choice == '6':
            print("\nğŸ‘‹ è°¢è°¢ä½¿ç”¨ï¼")
            print("ğŸ’¾ ç”Ÿæˆçš„æ–‡ä»¶:")
            print("  - è¯†åˆ«ç»“æœ.png (å•å¼ è¯†åˆ«ç»“æœ)")
            print("  - æµ‹è¯•é›†è¯†åˆ«.png (éšæœºæµ‹è¯•ç»“æœ)")
            print("  - my_traffic_classifier.keras (è®­ç»ƒå¥½çš„æ¨¡å‹)")
            break

        else:
            print("âŒ æ— æ•ˆé€‰é¡¹ï¼Œè¯·é‡è¯•")


# æ·»åŠ è¿™ä¸ªï¼Œç¡®ä¿èƒ½ç›´æ¥è¿è¡Œ
if __name__ == "__main__":
    # æ£€æŸ¥TensorFlowè­¦å‘Šï¼Œä½†ç»§ç»­è¿è¡Œ
    import warnings

    warnings.filterwarnings('ignore', category=UserWarning)

    main()